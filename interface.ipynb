{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e460cf0-817a-4285-8c90-43a32477a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained model (ensure the path to the model is correct)\n",
    "model = tf.keras.models.load_model(r\"C:\\Users\\91636\\Downloads\\my_model.h5\")  # Replace with your model's path\n",
    "\n",
    "# Corrected Class Names (Ensure this matches the model's output order)\n",
    "# Swap the order to fix the issue based on observed mismatches\n",
    "class_names = ['Benign', 'Malignant', 'Non-Cancerous']\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Resize the image to 256x256 without scaling.\n",
    "    Rescaling is already handled in the model.\n",
    "    \"\"\"\n",
    "    image = image.resize((256, 256))  # Resize to match model input size\n",
    "    image = np.array(image)  # Convert to NumPy array\n",
    "    if len(image.shape) == 2:  # If grayscale, convert to RGB\n",
    "        image = np.stack([image] * 3, axis=-1)\n",
    "    return image  # Return image without scaling to [0, 1]\n",
    "\n",
    "# Prediction Function\n",
    "def predict(image):\n",
    "    \"\"\"\n",
    "    Run predictions on a single preprocessed image.\n",
    "    \"\"\"\n",
    "    # Add batch dimension to match model input shape\n",
    "    input_array = np.expand_dims(image, axis=0)\n",
    "    print(\"Input shape to model:\", input_array.shape)  # Debugging\n",
    "\n",
    "    # Get predictions\n",
    "    probabilities = model.predict(input_array)\n",
    "    print(\"Raw probabilities:\", probabilities)  # Debugging\n",
    "\n",
    "    # Get the predicted class and confidence\n",
    "    predicted_class_idx = np.argmax(probabilities, axis=1)[0]\n",
    "    confidence = probabilities[0][predicted_class_idx]\n",
    "\n",
    "    # Return the corrected class name and confidence\n",
    "    return class_names[predicted_class_idx], round(confidence * 100, 2)\n",
    "\n",
    "# Gradio Interface Function\n",
    "def gradio_interface(image):\n",
    "    \"\"\"\n",
    "    Process the uploaded image and return the prediction result.\n",
    "    \"\"\"\n",
    "    preprocessed_image = preprocess_image(image)  # Preprocess the image\n",
    "    prediction, confidence = predict(preprocessed_image)  # Get predictions\n",
    "    return f\"{prediction} ({confidence}%)\"  # Format the output for display\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks(css=\"\"\"\n",
    "    body {\n",
    "        background-color: #f5f5f5;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "    .gradio-container {\n",
    "        background: linear-gradient(to bottom right, #ffffff, #e6e6e6);\n",
    "        border-radius: 15px;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "        padding: 20px;\n",
    "    }\n",
    "    h1, .gr-markdown {\n",
    "        color: #003366;\n",
    "        text-align: center;\n",
    "    }\n",
    "    h1 {\n",
    "        font-size: 2.5rem;\n",
    "    }\n",
    "    .gr-markdown {\n",
    "        font-size: 1.2rem;\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "    .gr-button {\n",
    "        background-color: #003366;\n",
    "        color: white;\n",
    "        border-radius: 5px;\n",
    "        padding: 10px 20px;\n",
    "    }\n",
    "    .gr-button:hover {\n",
    "        background-color: #00509e;\n",
    "    }\n",
    "\"\"\") as demo:\n",
    "    gr.Markdown(\"\"\"# Cancer Classification System\"\"\")\n",
    "    gr.Markdown(\n",
    "        \"\"\"<p style='color: #003366;'>Upload an MRI image to classify it as Non-Cancerous, Benign, or Malignant. This system leverages a deep learning model trained on MRI data to provide accurate predictions.</p>\"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        image_input = gr.Image(type=\"pil\", label=\"Upload MRI Image\", image_mode=\"RGB\")\n",
    "        output_predictions = gr.Textbox(label=\"Predictions (Class, Confidence)\")\n",
    "\n",
    "    submit_button = gr.Button(\"Submit\")\n",
    "\n",
    "    submit_button.click(\n",
    "        fn=gradio_interface,\n",
    "        inputs=image_input,\n",
    "        outputs=[output_predictions]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4182d405-3df6-45ba-8e80-9e0b737ecb90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
